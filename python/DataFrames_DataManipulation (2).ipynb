{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bigger-filling",
   "metadata": {},
   "source": [
    "## Data Frames and Data Manipulation\n",
    "\n",
    "### Introduction of Data Frames\n",
    "\n",
    "Data Frame is a two dimensional data structure where the data is arranged in a tabular format like excel in rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daily-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Pandas Library\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "purple-thousand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "  ProgLang\n",
      "0   Python\n",
      "1        R\n",
      "2        C\n",
      "3    Julia\n",
      "4     Java\n",
      "5    Scala\n"
     ]
    }
   ],
   "source": [
    "## Creating a dataframe from a list\n",
    "langs = ['Python','R','C','Julia','Java','Scala']\n",
    "\n",
    "## Creating dataframe using pd.DataFrame]\n",
    "#df_langs = pd.DataFrame(langs)\n",
    "\n",
    "#df_langs = pd.DataFrame(langs)\n",
    "df_langs = pd.DataFrame(langs, columns = ['ProgLang'])\n",
    "## Printing dataframe df_langs\n",
    "print(type(df_langs))\n",
    "print(df_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d753bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[444 401 499 474 359 461 425 376 431 411]\n",
      "   Marks\n",
      "0    444\n",
      "1    401\n",
      "2    499\n",
      "3    474\n",
      "4    359\n",
      "5    461\n",
      "6    425\n",
      "7    376\n",
      "8    431\n",
      "9    411\n"
     ]
    }
   ],
   "source": [
    "markslist = np.random.randint(300,500,10)\n",
    "print(markslist)\n",
    "\n",
    "df_marks = pd.DataFrame(markslist, columns=['Marks'])\n",
    "print(df_marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addressed-figure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Store  Sales\n",
      "0    Apple  74000\n",
      "1  Samsung  89770\n",
      "2     Vivo  56700\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "## Creating a dataframe from list of lists\n",
    "store_sales=[['Apple',74000],['Samsung',89770],['Vivo',56700]]\n",
    "\n",
    "## Creating a dataframe\n",
    "df_phonesales = pd.DataFrame(store_sales, columns = ['Store','Sales'])\n",
    "\n",
    "print(df_phonesales)\n",
    "print(type(df_phonesales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b20eecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': ['Anand', 'Akshay', 'Arvind', 'Abinav'], 'Marks': [435, 345, 389, 498]}\n",
      "  StuName  StuMarks\n",
      "0   Anand       435\n",
      "1  Akshay       345\n",
      "2  Arvind       389\n",
      "3  Abinav       498\n"
     ]
    }
   ],
   "source": [
    "marksdict = {'name': ['Anand', 'Akshay', 'Arvind', 'Abinav'],\n",
    "             'Marks': [435, 345, 389, 498]}\n",
    "\n",
    "markslist = [['Anand',435], ['Akshay',345], ['Arvind',389], ['Abinav',498]]\n",
    "print(marksdict)                    \n",
    "df_marks = pd.DataFrame(markslist, columns=['StuName','StuMarks'])\n",
    "print(df_marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "imposed-symposium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biscuits</td>\n",
       "      <td>6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beverages</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coffee</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tea</td>\n",
       "      <td>8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Milk</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product  Sales\n",
       "0   Biscuits   6500\n",
       "1  Beverages   7000\n",
       "2     Snacks   8500\n",
       "3     Coffee   9000\n",
       "4        Tea   8900\n",
       "5       Milk  10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a dataframe from a dictionary\n",
    "\n",
    "prod_dict = {'Product':['Biscuits','Beverages','Snacks','Coffee','Tea','Milk'], \n",
    "             'Sales':[6500,7000,8500,9000,8900,10000]}\n",
    "           \n",
    "## Creating a dataframe from a dictionary\n",
    "df_product = pd.DataFrame(prod_dict)\n",
    "\n",
    "df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attached-footwear",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>Biscuits</td>\n",
       "      <td>6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>Beverages</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>Coffee</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>Tea</td>\n",
       "      <td>8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>Milk</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product  Sales\n",
       "A   Biscuits   6500\n",
       "B  Beverages   7000\n",
       "C     Snacks   8500\n",
       "D     Coffee   9000\n",
       "E        Tea   8900\n",
       "F       Milk  10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a dataframe from a dictionary with index\n",
    "\n",
    "prod_dict = {'Product':['Biscuits','Beverages','Snacks','Coffee','Tea','Milk'], \n",
    "             'Sales':[6500,7000,8500,9000,8900,10000]}\n",
    "           \n",
    "## Creating a dataframe\n",
    "df_product = pd.DataFrame(prod_dict, index=['A','B','C','D','E','F'])\n",
    "\n",
    "df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "referenced-bristol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    6500\n",
       "E    8900\n",
       "Name: Sales, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product.iloc[[0,4],1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f88120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E    8900\n",
       "B    7000\n",
       "Name: Sales, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product.iloc[[4,1],1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1536891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    6500\n",
       "D    9000\n",
       "Name: Sales, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product.loc[['A','D'],'Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced71f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    7000\n",
       "C    8500\n",
       "Name: Sales, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product.loc[['B','C'],'Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "several-glasgow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store-A</th>\n",
       "      <th>Store-B</th>\n",
       "      <th>Store-C</th>\n",
       "      <th>Store-D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65000</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75000</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store-A  Store-B  Store-C  Store-D\n",
       "0    65000  70000.0      NaN  45750.0\n",
       "1    75000  45000.0  95000.0      NaN\n",
       "2    55000      NaN  65000.0      NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a dataframe from a list dictionaries\n",
    "\n",
    "br_sales = [{'Store-A':65000,'Store-B':70000,'Store-D':45750}, \n",
    "             {'Store-A':75000,'Store-B':45000,'Store-C':95000},\n",
    "            {'Store-A':55000,'Store-C':65000}]\n",
    "           \n",
    "## Creating a dataframe\n",
    "df_brsales = pd.DataFrame(br_sales)\n",
    "\n",
    "df_brsales = df_brsales[['Store-A','Store-B','Store-C','Store-D']]\n",
    "df_brsales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bearing-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    70000.0\n",
      "1    45000.0\n",
      "2        NaN\n",
      "Name: Store-B, dtype: float64\n",
      "   Store-A  Store-C\n",
      "0    65000      NaN\n",
      "1    75000  95000.0\n",
      "2    55000  65000.0\n",
      "\n",
      " <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "## To select a single column from a dataframe\n",
    "print(df_brsales['Store-B'])\n",
    "\n",
    "## To select an individual Column from dataframe\n",
    "print(df_brsales[['Store-A','Store-C']])\n",
    "\n",
    "## Printing the type\n",
    "print('\\n',type(df_product['Product']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-impossible",
   "metadata": {},
   "source": [
    "### Reading Data from various type of Files\n",
    "\n",
    "Pandas has number of functions to read data from various kind of files, like, csv, text, excel, JSON, HTML, etc.  Even we can extract and load a file from a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "consistent-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "  Month Store  Sales\n",
      "0   Jan     A  31037\n",
      "1   Jan     B  20722\n",
      "2   Jan     C  24557\n",
      "3   Jan     D  34649\n",
      "4   Jan     E  29795\n",
      "5   Feb     A  29133\n",
      "6   Feb     B  22695\n",
      "   Month Store  Sales\n",
      "17   Apr     C  47488\n",
      "18   Apr     D  25432\n",
      "19   Apr     E  33880\n",
      "20   May     A  29487\n",
      "21   May     B  40001\n",
      "22   May     C  46482\n",
      "23   May     D  46313\n",
      "24   May     E  47594\n"
     ]
    }
   ],
   "source": [
    "## Reading from a CSV File\n",
    "df_salescsv = pd.read_csv('F:/Python Learning/Imarticus/Datasets/Pandas/bigmarket.csv')\n",
    "print(type(df_salescsv))\n",
    "\n",
    "print(df_salescsv.head(7))\n",
    "print(df_salescsv.tail(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "precise-porcelain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Store</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>A</td>\n",
       "      <td>31037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>B</td>\n",
       "      <td>20722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan</td>\n",
       "      <td>C</td>\n",
       "      <td>24557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan</td>\n",
       "      <td>D</td>\n",
       "      <td>34649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan</td>\n",
       "      <td>E</td>\n",
       "      <td>29795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feb</td>\n",
       "      <td>A</td>\n",
       "      <td>29133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Feb</td>\n",
       "      <td>B</td>\n",
       "      <td>22695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Feb</td>\n",
       "      <td>C</td>\n",
       "      <td>28312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Feb</td>\n",
       "      <td>D</td>\n",
       "      <td>31454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Feb</td>\n",
       "      <td>E</td>\n",
       "      <td>46267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>March</td>\n",
       "      <td>A</td>\n",
       "      <td>32961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>March</td>\n",
       "      <td>B</td>\n",
       "      <td>26451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>March</td>\n",
       "      <td>C</td>\n",
       "      <td>47814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>March</td>\n",
       "      <td>D</td>\n",
       "      <td>36069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>March</td>\n",
       "      <td>E</td>\n",
       "      <td>31874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Apr</td>\n",
       "      <td>A</td>\n",
       "      <td>27253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Apr</td>\n",
       "      <td>B</td>\n",
       "      <td>40241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Apr</td>\n",
       "      <td>C</td>\n",
       "      <td>47488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Apr</td>\n",
       "      <td>D</td>\n",
       "      <td>25432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Apr</td>\n",
       "      <td>E</td>\n",
       "      <td>33880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>May</td>\n",
       "      <td>A</td>\n",
       "      <td>29487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>May</td>\n",
       "      <td>B</td>\n",
       "      <td>40001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>May</td>\n",
       "      <td>C</td>\n",
       "      <td>46482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>May</td>\n",
       "      <td>D</td>\n",
       "      <td>46313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>May</td>\n",
       "      <td>E</td>\n",
       "      <td>47594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month Store  Sales\n",
       "0     Jan     A  31037\n",
       "1     Jan     B  20722\n",
       "2     Jan     C  24557\n",
       "3     Jan     D  34649\n",
       "4     Jan     E  29795\n",
       "5     Feb     A  29133\n",
       "6     Feb     B  22695\n",
       "7     Feb     C  28312\n",
       "8     Feb     D  31454\n",
       "9     Feb     E  46267\n",
       "10  March     A  32961\n",
       "11  March     B  26451\n",
       "12  March     C  47814\n",
       "13  March     D  36069\n",
       "14  March     E  31874\n",
       "15    Apr     A  27253\n",
       "16    Apr     B  40241\n",
       "17    Apr     C  47488\n",
       "18    Apr     D  25432\n",
       "19    Apr     E  33880\n",
       "20    May     A  29487\n",
       "21    May     B  40001\n",
       "22    May     C  46482\n",
       "23    May     D  46313\n",
       "24    May     E  47594"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading from excel file\n",
    "df_salesxlsx = pd.read_excel('datasets/pandas/bigmarket.xlsx')\n",
    "df_salesxlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "605cbe28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "5\n",
      "['BATCH 3 - ECE & EI (4)', 'BATCH 3 - 19th July', 'BATCH 3 - 20th July', 'BATCH 3 - 21st July', 'BATCH 3 - 23rd July']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "files = pd.ExcelFile('../Sample_Data/Attendance.xlsx')\n",
    "df = files.parse()\n",
    "print(type(files.parse(sheet_name=1)))\n",
    "#print(df)\n",
    "print(len(files.sheet_names))\n",
    "df_list =[]\n",
    "for shindex in range(len(files.sheet_names)):\n",
    "    df_list.append(files.parse(sheet_name=shindex))\n",
    "print(files.sheet_names)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03ba892e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   APPLN_NO CANDIDATE ID  BATCH              CANDIDATE_NAME      MOBILE  \\\n",
       " 0   TA-1919       C-5860      3              ANJALI   SINGH  7411913270   \n",
       " 1   TA-1918       C-5861      3       ANJALI  KRISHNA SINGH  7338239779   \n",
       " 2   TA-1986       C-5955      3                  ati   kant  9538167584   \n",
       " 3   TA-1916       C-5821      3                CHAITHRA   S  9538271916   \n",
       " 4   TA-1928       C-5837      3                 Chaitra   C  8892418216   \n",
       " ..      ...          ...    ...                         ...         ...   \n",
       " 57  TA-1954       C-5921      3              Vaibhavi   H L  9448380718   \n",
       " 58  TA-1882       C-5862      3  Gayathri  Hudhugur Bhushan  9591505647   \n",
       " 59  TA-1874       C-5823      3   Aishwarya  Ravindra Patil  9513479281   \n",
       " 60  TA-1852       C-5805      2          Vishnu   Kulkarni   9611356743   \n",
       " 61  TA-1949       C-5799      2             Ankith R  Patil  8431355554   \n",
       " \n",
       "                                 EMAIL  \\\n",
       " 0       anjalisingh.jsr1706@gmail.com   \n",
       " 1        anjalisingh1111.ak@gmail.com   \n",
       " 2             atikantraj123@gmail.com   \n",
       " 3             chaithra.s164@gmail.com   \n",
       " 4   chaitrachandrashekar004@gmail.com   \n",
       " ..                                ...   \n",
       " 57         vaibhaviprasad97@gmail.com   \n",
       " 58  Gayathrihudhugurbhushan@gmail.com   \n",
       " 59      aishwaryapatil61996@gmail.com   \n",
       " 60        vishnukulkarni627@gmail.com   \n",
       " 61      ankitrpatilankit007@gmail.com   \n",
       " \n",
       "                              GRAD SPECIALIZATION  2018-07-19 00:00:00  \\\n",
       " 0    Electronics and Communication Engineering                    NaN   \n",
       " 1    Electronics and Communication Engineering                    NaN   \n",
       " 2    Electronics and Communication Engineering                    NaN   \n",
       " 3    Electronics and Communication Engineering                    NaN   \n",
       " 4    Electronics and Communication Engineering                    NaN   \n",
       " ..                                           ...                  ...   \n",
       " 57   Electronics and Instrumentation Engineering                  NaN   \n",
       " 58  Electronics and Instrumentation Engineering                   NaN   \n",
       " 59    Electronics and instrumentation technology                  NaN   \n",
       " 60                 electronic and communication                   NaN   \n",
       " 61                 Electronics & Instrumentation                  NaN   \n",
       " \n",
       "     2018-07-20 00:00:00  2018-07-21 00:00:00  2018-07-23 00:00:00  \\\n",
       " 0                   NaN                  NaN                  NaN   \n",
       " 1                   NaN                  NaN                  NaN   \n",
       " 2                   NaN                  NaN                  NaN   \n",
       " 3                   NaN                  NaN                  NaN   \n",
       " 4                   NaN                  NaN                  NaN   \n",
       " ..                  ...                  ...                  ...   \n",
       " 57                  NaN                  NaN                  NaN   \n",
       " 58                  NaN                  NaN                  NaN   \n",
       " 59                  NaN                  NaN                  NaN   \n",
       " 60                  NaN                  NaN                  NaN   \n",
       " 61                  NaN                  NaN                  NaN   \n",
       " \n",
       "     2018-07-24 00:00:00  2018-07-25 00:00:00  \n",
       " 0                   NaN                  NaN  \n",
       " 1                   NaN                  NaN  \n",
       " 2                   NaN                  NaN  \n",
       " 3                   NaN                  NaN  \n",
       " 4                   NaN                  NaN  \n",
       " ..                  ...                  ...  \n",
       " 57                  NaN                  NaN  \n",
       " 58                  NaN                  NaN  \n",
       " 59                  NaN                  NaN  \n",
       " 60                  NaN                  NaN  \n",
       " 61                  NaN                  NaN  \n",
       " \n",
       " [62 rows x 13 columns],\n",
       "    APPLN_NO CANDIDATE ID  BATCH               CANDIDATE_NAME      MOBILE  \\\n",
       " 0   TA-1919       C-5860      3               ANJALI   SINGH  7411913270   \n",
       " 1   TA-1918       C-5861      3        ANJALI  KRISHNA SINGH  7338239779   \n",
       " 2   TA-1910       C-5874      3                Ekta   kumari  8951250845   \n",
       " 3   TA-2991       C-5721      3                 Hemanath   V  9035358009   \n",
       " 4   TA-1985       C-5689      3          Jayanth   Kumar K H  8880505289   \n",
       " 5   TA-1996       C-5750      3                  Jayanth   M  8123331652   \n",
       " 6   TA-2005       C-5747      3                 Kavana   M A  7829456170   \n",
       " 7   TA-1944       C-5759      3             Kendole   Nikhil  9902848074   \n",
       " 8   TA-1988       C-5734      3                Md  Numan Ali  7795524450   \n",
       " 9   TA-2009       C-5779      3         Mohamed  Danish Khan  8050998190   \n",
       " 10  TA-1972       C-5697      3             Nischal  Simha S  9844561360   \n",
       " 11  TA-1935       C-5890      3            RACHANA  R SHETTY  9880917408   \n",
       " 12  TA-2018       C-5961      3                Rakshitha   N  8217345227   \n",
       " 13  TA-2060       C-6023      3  Ramkumar   Shrikant  Gurav   8549065626   \n",
       " 14  TA-1934       C-5897      3               ramya   shetty  9739463863   \n",
       " 15  TA-1921       C-5873      3                    REKHA   J  9945860998   \n",
       " 16  TA-3006       C-7157      3                  Sagar   S B  7022306282   \n",
       " 17  TA-1873       C-5727      3               Saurav   Kumar  9620925027   \n",
       " 18  TA-2040       C-5984      3       shekhar  pratap  singh  8105221303   \n",
       " 19  TA-1931       C-5868      3         SHIKHA  PRABHA GUPTA  8809256435   \n",
       " 20  TA-1830       C-5717      3           Shreegowri A Nagur  9108172408   \n",
       " 21  TA-1932       C-5881      3               sonali   singh  9008946815   \n",
       " 22  TA-1946       C-5792      3           SPOORTHI    THOTAD  8618808727   \n",
       " 23  TA-2025       C-5785      3               Sumanth   Naag  8892883828   \n",
       " 24  TA-1976       C-5692      3                  VARUN   K V  9663142145   \n",
       " 25  TA-2043       C-5981      3               VISHAL   KARUR  8792170783   \n",
       " 26  TA-1785       C-5704      3                 YAMINI   V S  9035455297   \n",
       " 27  TA-2020       C-5940      3       YASHWANTH   K  A Yashu  7899354199   \n",
       " 28  TA-1813       C-5710      3                   Kavya   Kv  9108643332   \n",
       " 29  TA-1845       C-5707      3                Kripa   Kiran  8971411966   \n",
       " 30  TA-1893       C-5813      3                 rakesh   s g  8884538997   \n",
       " 31  TA-1868       C-5817      3            Ravisham   Santha  7259954569   \n",
       " 32  TA-1892       C-5819      3                   yogesh   b  9036892027   \n",
       " 33  TA-1811       C-5761      3           Bhargavi  S Badami  9148588212   \n",
       " 34  TA-1871       C-5700      3                  Maithri   S  8970500810   \n",
       " 35  TA-1806       C-5703      3               Shree   Varsha  9164618240   \n",
       " 36  TA-1882       C-5862      3   Gayathri  Hudhugur Bhushan  9591505647   \n",
       " 37  TA-1874       C-5823      3    Aishwarya  Ravindra Patil  9513479281   \n",
       " 38  TA-1852       C-5805      2           Vishnu   Kulkarni   9611356743   \n",
       " 39  TA-1949       C-5799      2              Ankith R  Patil  8431355554   \n",
       " \n",
       "                                 EMAIL  \\\n",
       " 0       anjalisingh.jsr1706@gmail.com   \n",
       " 1        anjalisingh1111.ak@gmail.com   \n",
       " 2     ektakumari.1js15ec028@gmail.com   \n",
       " 3       hemanath.1js15ec126@gmail.com   \n",
       " 4            jayanthhkumarr@gmail.com   \n",
       " 5               jayanthjanu@gmail.com   \n",
       " 6                  kkavanaa@gmail.com   \n",
       " 7            nikhil.kendole@gmail.com   \n",
       " 8                  zeenuman@gmail.com   \n",
       " 9            profmaildanish@gmail.com   \n",
       " 10            nischalsimhas@gmail.com   \n",
       " 11            rracchushetty@gmail.com   \n",
       " 12       raksharakshithan95@gmail.com   \n",
       " 13      ramkumar.1js15ec071@gmail.com   \n",
       " 14           ramyashetty148@gmail.com   \n",
       " 15                 rekha97j@gmail.com   \n",
       " 16         sagar.1js15ec123@gmail.com   \n",
       " 17        kumarsaurav655655@gmail.com   \n",
       " 18       shekhar.1js15ec090@gmail.com   \n",
       " 19      shikha.anand11@rediffmail.com   \n",
       " 20       gowrinagur08031997@gmail.com   \n",
       " 21           sonalisingh772@gmail.com   \n",
       " 22         spoorthithotad19@gmail.com   \n",
       " 23             sumanthnaagk@gmail.com   \n",
       " 24            varunvkrishna@gmail.com   \n",
       " 25            vishalkarur12@gmail.com   \n",
       " 26        yamini.1js15ec121@gmail.com   \n",
       " 27            yashwanthka97@gmail.com   \n",
       " 28               kavyakv345@gmail.com   \n",
       " 29             mailkripa.18@gmail.com   \n",
       " 30               sgrakesh39@gmail.com   \n",
       " 31          santha.ravisham@gmail.com   \n",
       " 32                 yogs3397@gmail.com   \n",
       " 33          bhargavisbadami@gmail.com   \n",
       " 34              maithri.s97@gmail.com   \n",
       " 35            varsha.syrena@gmail.com   \n",
       " 36  Gayathrihudhugurbhushan@gmail.com   \n",
       " 37      aishwaryapatil61996@gmail.com   \n",
       " 38        vishnukulkarni627@gmail.com   \n",
       " 39      ankitrpatilankit007@gmail.com   \n",
       " \n",
       "                              GRAD SPECIALIZATION  2018-07-19 00:00:00  \\\n",
       " 0    Electronics and Communication Engineering                    NaN   \n",
       " 1    Electronics and Communication Engineering                    NaN   \n",
       " 2    Electronics and Communication Engineering                    NaN   \n",
       " 3    Electronics and Communication Engineering                    NaN   \n",
       " 4    Electronics and Communication Engineering                    NaN   \n",
       " 5    Electronics and Communication Engineering                    NaN   \n",
       " 6    Electronics and Communication Engineering                    NaN   \n",
       " 7    Electronics and Communication Engineering                    NaN   \n",
       " 8    Electronics and Communication Engineering                    NaN   \n",
       " 9    Electronics and Communication Engineering                    NaN   \n",
       " 10   Electronics and Communication Engineering                    NaN   \n",
       " 11   Electronics and Communication Engineering                    NaN   \n",
       " 12   Electronics and Communication Engineering                    NaN   \n",
       " 13   Electronics and Communication Engineering                    NaN   \n",
       " 14   Electronics and Communication Engineering                    NaN   \n",
       " 15   Electronics and Communication Engineering                    NaN   \n",
       " 16   Electronics and Communication Engineering                    NaN   \n",
       " 17   Electronics and Communication Engineering                    NaN   \n",
       " 18   Electronics and Communication Engineering                    NaN   \n",
       " 19   Electronics and Communication Engineering                    NaN   \n",
       " 20   Electronics and Communication Engineering                    NaN   \n",
       " 21   Electronics and Communication Engineering                    NaN   \n",
       " 22   Electronics and Communication Engineering                    NaN   \n",
       " 23   Electronics and Communication Engineering                    NaN   \n",
       " 24   Electronics and Communication Engineering                    NaN   \n",
       " 25   Electronics and Communication Engineering                    NaN   \n",
       " 26   Electronics and Communication Engineering                    NaN   \n",
       " 27   Electronics and Communication Engineering                    NaN   \n",
       " 28               Electronics and instrumentation                  NaN   \n",
       " 29               Electronics and instrumentation                  NaN   \n",
       " 30               ELECTRONICS and INSTRUMENTATION                  NaN   \n",
       " 31               Electronics and instrumentation                  NaN   \n",
       " 32               ELECTRONICS AND INSTRUMENTATION                  NaN   \n",
       " 33              Electronics and Instrumentation                   NaN   \n",
       " 34   Electronics and Instrumentation Engineering                  NaN   \n",
       " 35   Electronics and instrumentation engineering                  NaN   \n",
       " 36  Electronics and Instrumentation Engineering                   NaN   \n",
       " 37    Electronics and instrumentation technology                  NaN   \n",
       " 38                 electronic and communication                   NaN   \n",
       " 39                 Electronics & Instrumentation                  NaN   \n",
       " \n",
       "     2018-07-20 00:00:00  2018-07-21 00:00:00  2018-07-23 00:00:00  \\\n",
       " 0                   NaN                  NaN                  NaN   \n",
       " 1                   NaN                  NaN                  NaN   \n",
       " 2                   NaN                  NaN                  NaN   \n",
       " 3                   NaN                  NaN                  NaN   \n",
       " 4                   NaN                  NaN                  NaN   \n",
       " 5                   NaN                  NaN                  NaN   \n",
       " 6                   NaN                  NaN                  NaN   \n",
       " 7                   NaN                  NaN                  NaN   \n",
       " 8                   NaN                  NaN                  NaN   \n",
       " 9                   NaN                  NaN                  NaN   \n",
       " 10                  NaN                  NaN                  NaN   \n",
       " 11                  NaN                  NaN                  NaN   \n",
       " 12                  NaN                  NaN                  NaN   \n",
       " 13                  NaN                  NaN                  NaN   \n",
       " 14                  NaN                  NaN                  NaN   \n",
       " 15                  NaN                  NaN                  NaN   \n",
       " 16                  NaN                  NaN                  NaN   \n",
       " 17                  NaN                  NaN                  NaN   \n",
       " 18                  NaN                  NaN                  NaN   \n",
       " 19                  NaN                  NaN                  NaN   \n",
       " 20                  NaN                  NaN                  NaN   \n",
       " 21                  NaN                  NaN                  NaN   \n",
       " 22                  NaN                  NaN                  NaN   \n",
       " 23                  NaN                  NaN                  NaN   \n",
       " 24                  NaN                  NaN                  NaN   \n",
       " 25                  NaN                  NaN                  NaN   \n",
       " 26                  NaN                  NaN                  NaN   \n",
       " 27                  NaN                  NaN                  NaN   \n",
       " 28                  NaN                  NaN                  NaN   \n",
       " 29                  NaN                  NaN                  NaN   \n",
       " 30                  NaN                  NaN                  NaN   \n",
       " 31                  NaN                  NaN                  NaN   \n",
       " 32                  NaN                  NaN                  NaN   \n",
       " 33                  NaN                  NaN                  NaN   \n",
       " 34                  NaN                  NaN                  NaN   \n",
       " 35                  NaN                  NaN                  NaN   \n",
       " 36                  NaN                  NaN                  NaN   \n",
       " 37                  NaN                  NaN                  NaN   \n",
       " 38                  NaN                  NaN                  NaN   \n",
       " 39                  NaN                  NaN                  NaN   \n",
       " \n",
       "     2018-07-24 00:00:00  2018-07-25 00:00:00  \n",
       " 0                   NaN                  NaN  \n",
       " 1                   NaN                  NaN  \n",
       " 2                   NaN                  NaN  \n",
       " 3                   NaN                  NaN  \n",
       " 4                   NaN                  NaN  \n",
       " 5                   NaN                  NaN  \n",
       " 6                   NaN                  NaN  \n",
       " 7                   NaN                  NaN  \n",
       " 8                   NaN                  NaN  \n",
       " 9                   NaN                  NaN  \n",
       " 10                  NaN                  NaN  \n",
       " 11                  NaN                  NaN  \n",
       " 12                  NaN                  NaN  \n",
       " 13                  NaN                  NaN  \n",
       " 14                  NaN                  NaN  \n",
       " 15                  NaN                  NaN  \n",
       " 16                  NaN                  NaN  \n",
       " 17                  NaN                  NaN  \n",
       " 18                  NaN                  NaN  \n",
       " 19                  NaN                  NaN  \n",
       " 20                  NaN                  NaN  \n",
       " 21                  NaN                  NaN  \n",
       " 22                  NaN                  NaN  \n",
       " 23                  NaN                  NaN  \n",
       " 24                  NaN                  NaN  \n",
       " 25                  NaN                  NaN  \n",
       " 26                  NaN                  NaN  \n",
       " 27                  NaN                  NaN  \n",
       " 28                  NaN                  NaN  \n",
       " 29                  NaN                  NaN  \n",
       " 30                  NaN                  NaN  \n",
       " 31                  NaN                  NaN  \n",
       " 32                  NaN                  NaN  \n",
       " 33                  NaN                  NaN  \n",
       " 34                  NaN                  NaN  \n",
       " 35                  NaN                  NaN  \n",
       " 36                  NaN                  NaN  \n",
       " 37                  NaN                  NaN  \n",
       " 38                  NaN                  NaN  \n",
       " 39                  NaN                  NaN  ]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e2cc646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Order_ID', 'Cust_ID', 'Order'], dtype='object')\n",
      "Index(['ORDER_ID', 'CUST_ID', 'ORDER'], dtype='object')\n",
      "   ORDER_ID  CUST_ID  ORDER\n",
      "0       222      101    789\n",
      "1       223      102    465\n",
      "2       224      103    674\n",
      "3       225      104    564\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('datasets/pandas/customer1.xlsx', sheet_name='Order')\n",
    "print(df.columns)\n",
    "df.columns = df.columns.str.upper()\n",
    "print(df.columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d87374dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.excel._base.ExcelFile'>\n",
      "   Cust_ID      Name\n",
      "0      101    Olivia\n",
      "1      102  Will LLC\n",
      "2      103    Sophia\n",
      "3      104  Isabella\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Cusotmer', 'Order']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reading multiple sheet in a single read\n",
    "files = pd.ExcelFile('datasets/pandas/customer1.xlsx')\n",
    "print(type(files))\n",
    "\n",
    "print(files.parse(sheet_name='Cusotmer'))\n",
    "files.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5d7f702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cust_ID      Name\n",
      "0      101    Olivia\n",
      "1      102  Will LLC\n",
      "2      103    Sophia\n",
      "3      104  Isabella\n",
      "   Order_ID  Cust_ID  Order\n",
      "0       222      101    789\n",
      "1       223      102    465\n",
      "2       224      103    674\n",
      "3       225      104    564\n"
     ]
    }
   ],
   "source": [
    "df_list=[]\n",
    "for shname in files.sheet_names:\n",
    "    df_list.append(files.parse(sheet_name=shname))\n",
    "    \n",
    "for df in df_list:\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "crucial-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading csv file from a zip file\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "photographic-beatles",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bigmarket.csv']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"There is no item named 'Pandas/bigmarket.csv' in the archive\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6652/667197845.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datasets/pandas/bigmarket.zip\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pandas/bigmarket.csv\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mdf_sales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_sales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[0;32m   1512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m             \u001b[1;31m# Get info object for name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m             \u001b[0mzinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mgetinfo\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1439\u001b[0m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNameToInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m             raise KeyError(\n\u001b[0m\u001b[0;32m   1442\u001b[0m                 'There is no item named %r in the archive' % name)\n\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"There is no item named 'Pandas/bigmarket.csv' in the archive\""
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile(\"datasets/pandas/bigmarket.zip\") as Z:\n",
    "    print(Z.namelist())\n",
    "    with Z.open(\"Pandas/bigmarket.csv\") as f:\n",
    "        df_sales = pd.read_csv(f)\n",
    "        print(df_sales.head())\n",
    "\n",
    "#df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d0e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"datasets/pandas.zip\") as Z:\n",
    "    for fname in Z.namelist():\n",
    "        print(fname)\n",
    "    with Z.open(\"Pandas/bigmarket.csv\") as f:\n",
    "        df_sales = pd.read_csv(f)\n",
    "        print(df_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-photograph",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading from a text (.txt) file\n",
    "df_sales = pd.read_csv('datasets/pandas/bigmarket.txt',sep='\\t')\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-adelaide",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading data from JSON file\n",
    "df_sales = pd.read_json('datasets/pandas/bigmarket.json')\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data = pd.read_csv('../Sample_Data/HR_Employee_Attrition.csv')\n",
    "print(hr_data.columns)\n",
    "print(hr_data.shape)\n",
    "print(hr_data.head())\n",
    "print(hr_data.tail())\n",
    "print(hr_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a27206",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138bc8af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('../Sample_Data/titanic_data.csv')\n",
    "print(df_titanic.info())\n",
    "print(df_titanic.describe())\n",
    "print(df_titanic.describe(include='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefe905",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29170948",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/pandas/bigmarket.html','r') as f:\n",
    "    df_sales = pd.read_html(f.read())\n",
    "\n",
    "print(type(df_sales))\n",
    "print(df_sales[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-vacuum",
   "metadata": {},
   "source": [
    "### Understanding the data from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To print the top 5 rows\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To print the bottom 5 rows\n",
    "df_sales.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using n parameter in head and tail functions to print more rows\n",
    "print(df_sales.head(n=10))\n",
    "\n",
    "print(df_sales.tail(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To get the shape of dataframe\n",
    "df_sales.shape\n",
    "\n",
    "## It has 15 rows and 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To know the data type for each column\n",
    "df_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can use info() to print all the above details.\n",
    "df_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-prophet",
   "metadata": {},
   "source": [
    "**info()** will print, the shape, data type and null values if any, index values, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-weekly",
   "metadata": {},
   "source": [
    "### Accessing Data Frames\n",
    "\n",
    "Data frames are accessed using .iloc and .loc to subset the data.  iloc uses the index whereas loc uses the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing the dataframe\n",
    "print(df_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83898068",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Using row_index and column_index\n",
    "##  .iloc[row_index, column_index]\n",
    "df_sales.iloc[:5,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting the data using iloc\n",
    "## Selecting 5 row onwards and all the columns\n",
    "df_sales.iloc[0:5,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving the name of the store of first two rows\n",
    "df_sales.iloc[[0,1],[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving the name of the store of first row\n",
    "df_sales.iloc[[0,1]][['Store','Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving 4th to 6th rows from the dataframe for all the columns\n",
    "## If we don't provide column index, by default it will print all the columns\n",
    "df_sales.iloc[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting all the rows and first two columns\n",
    "df_sales.iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving only Month and Sales Columns\n",
    "df_sales.iloc[:,[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-housing",
   "metadata": {},
   "source": [
    "### Accessing dataframe elements using .loc function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Displaying first five rows of df_sales\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving second row Sales value\n",
    "df_sales.loc[1]['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving first 3 row's Store and Sales values\n",
    "## .loc uses column names and row names\n",
    "## .loc[row_names, column_names]\n",
    "df_sales.loc[[0,1,2],['Store','Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving subset of data using condition\n",
    "df_sales[df_sales['Sales']>40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['Sales']>40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving sales between 40000 and 50000\n",
    "df_sales_40k_50k=df_sales[(df_sales.Sales >= 40000) & (df_sales.Sales <= 50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb4d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_40k_50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving sales > 40000\n",
    "df_sales[((df_sales.Sales > 40000) | (df_sales.Month == 'Feb'))]['Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering data with multiple conditions\n",
    "df_sales[(df_sales.Month == 'Jan') & (df_sales.Sales > 30000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-level",
   "metadata": {},
   "source": [
    "### Data frame Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorting the data frame using sales value - Default Ascending Order\n",
    "df_sales.sort_values(['Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For decending sorting, we have set ascending argument false\n",
    "df_sales.sort_values('Sales', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorting with multiple columns\n",
    "df_sales.sort_values(['Store','Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc950af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorting with multiple columns\n",
    "df_sales.sort_values(['Sales','Store'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsetting the rows and sorting using index \n",
    "df_sales[df_sales.Sales > 40000].sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ac690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3724ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.Embarked.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa313caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = df_titanic['Age']\n",
    "type(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-error",
   "metadata": {},
   "source": [
    "### Ranking in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating data frame using lists\n",
    "namelist = ['John','James','Amy','Robin','Smith','Bob','Kevin']\n",
    "verbal_score = [173, 149, 158, 158, 100, 158, 120] \n",
    "quant_score = [151, 154, 152,  92, 127, 116, 154]\n",
    "qualify =['Yes','Yes','Yes','No','No','Yes','Yes']\n",
    "\n",
    "datadict = {'name':namelist, 'Verbal_score':verbal_score, 'Quantitative_score':quant_score, 'Qualify':qualify}\n",
    "datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame(datadict)\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score.Verbal_score.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ranking using method='min'\n",
    "df_score['Verbal_Rank'] = df_score.Verbal_score.rank(method='min')\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c283353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score.Verbal_score.rank(method='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ranking using method='max'\n",
    "df_score['Verbal_Rank'] = df_score.Verbal_score.rank(method='max')\n",
    "print(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ranking using method='max'\n",
    "df_score['Verbal_Rank'] = df_score.Verbal_score.rank(method='dense')\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ranking using default method which is average\n",
    "df_score['Verbal_Rank'] = df_score.Verbal_score.rank()\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score['Quant_rank'] = np.NaN\n",
    "df_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b525f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score['Quant_rank'] = df_score.Quantitative_score.rank(method='min')\n",
    "df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-outline",
   "metadata": {},
   "source": [
    "### Dataframe Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the required Data\n",
    "df_sales1 = pd.read_excel('datasets/pandas/sales_transactions.xlsx',sheet_name=0)\n",
    "print(df_sales1.shape)\n",
    "print(df_sales1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the required Data\n",
    "df_sales2 = pd.read_excel('datasets/pandas/sales_transactions.xlsx',sheet_name=1)\n",
    "print(df_sales2.shape)\n",
    "print(df_sales2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008912da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the required Data\n",
    "df_sales3 = pd.read_excel('datasets/pandas/sales_transactions.xlsx',sheet_name=2)\n",
    "print(df_sales3.shape)\n",
    "print(df_sales3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenating both the dataframes\n",
    "df_sales = pd.concat([df_sales1, df_sales2, df_sales3])\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88290c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenating both the dataframes\n",
    "df_sales = pd.concat([df_sales1, df_sales2, df_sales3], ignore_index = True)\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using append\n",
    "df_sales = df_sales1.append([df_sales2,df_sales3], ignore_index = True)\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5435e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.sort_values(['account', 'ext price'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the required Data\n",
    "df_order1 = pd.read_excel('datasets/pandas/order.xlsx',sheet_name=0)\n",
    "df_order1 = df_order1.iloc[:,0:6]\n",
    "df_order1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the required Data\n",
    "df_order2 = pd.read_excel('datasets/pandas/order.xlsx',sheet_name=1)\n",
    "df_order2 = df_order2.iloc[:,0:3]\n",
    "df_order2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate horizontally using axis = 1 parameter\n",
    "df_order = pd.concat([df_order1, df_order2],axis=1)\n",
    "print(df_order)\n",
    "print(df_order.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-princeton",
   "metadata": {},
   "source": [
    "### Dataframe Joins\n",
    "\n",
    "The default join is 'left'.  You can specify the join method by option parameter 'how'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the data to demonstrate various types of joins\n",
    "df_cust1 = pd.read_excel('datasets/pandas/customer.xlsx',sheet_name=0)\n",
    "df_cust1 = df_cust1.set_index('Cust_ID')\n",
    "df_cust1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the data to demonstrate various types of joins\n",
    "df_cust2 = pd.read_excel('datasets/pandas/customer.xlsx',sheet_name=1)\n",
    "df_cust2 = df_cust2.set_index('Cust_ID')\n",
    "df_cust2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c31570",
   "metadata": {},
   "source": [
    "#### Default join (left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59936cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving Order details with customer info\n",
    "df_left = df_cust1.join(df_cust2,lsuffix='_cust', rsuffix='_ord', on='Cust_ID')\n",
    "df_left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-seminar",
   "metadata": {},
   "source": [
    "#### Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8817b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Retrieving Order details with customer info\n",
    "df_inner = df_cust1.join(df_cust2,lsuffix='_cust', rsuffix='_ord', on='Cust_ID', how = 'inner')\n",
    "df_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieving Order details with customer info\n",
    "df_cust1.set_index('Cust_ID').join(df_cust2.set_index('Cust_ID'), on='Cust_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since we already set the index from both df_cust1 and df_cust2, it uses those index.\n",
    "##  Now we can specify the in understand the columns from each data frame with thier suffix\n",
    "df_cust1.join(df_cust2, lsuffix='_cust', rsuffix='_ord')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-success",
   "metadata": {},
   "source": [
    "### Dataframe Merge\n",
    "\n",
    "Both ***joins and merge*** can be used to combines two dataframes but the join method combines two dataframes on the basis of their indexes whereas the merge method is more versatile and allows us to specify columns beside the index to join on for both dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the data to demonstrate various types of joins\n",
    "df_cust = pd.read_excel('datasets/pandas/Ecommerce_data.xlsx',sheet_name='Cust_data')\n",
    "df_cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the data to demonstrate various types of joins\n",
    "df_order = pd.read_excel('datasets/pandas/Ecommerce_data.xlsx',sheet_name='Ord_data')\n",
    "df_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-despite",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Dataframe merge - Inner is Default method.\n",
    "pd.merge(df_cust, df_order, on='Cust_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.read_excel('datasets/pandas/customer.xlsx',sheet_name=0)\n",
    "dfo = pd.read_excel('datasets/pandas/customer.xlsx',sheet_name=1)\n",
    "dfp = pd.read_excel('datasets/pandas/customer.xlsx',sheet_name=2)\n",
    "print(dfc)\n",
    "print(dfo)\n",
    "print(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging 3 different dataframes on differnt columns \n",
    "pd.merge(dfc, dfo, left_on = 'Custid', right_on='Cust_ID').merge(dfp, on = 'Order_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the index for both dataframes\n",
    "dfc = dfc.set_index('Custid')\n",
    "print(dfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = dfo.set_index('Cust_ID')\n",
    "dfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(dfc, dfo, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee43ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging the dataframe on different name on key columns, must use left_on and right_on to map \n",
    "## the key columns\n",
    "## Suppose if you want to join multiple columns, it should passed as list.\n",
    "pd.merge(dfc, dfo, left_on='Custid', right_on='Cust_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(dfc, dfo, left_on='Custid', right_on='Cust_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe merge - Outer\n",
    "pd.merge(df_cust, df_order, on='Cust_ID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe merge - Right\n",
    "pd.merge(df_cust, df_order, on='Cust_ID', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe merge - left\n",
    "pd.merge(df_cust, df_order, on='Cust_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order.set_index('Cust_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cust.set_index('Cust_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_cust, df_order, left_index = True, right_index = True)\n",
    "#pd.merge(df_cust, df_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.read_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-charleston",
   "metadata": {},
   "source": [
    "### Reshaping Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating data frame using lists\n",
    "namelist = ['John','James','Amy','Robin','Smith','Bob','Kevin']\n",
    "salary = np.random.randint(20000,50000,7) \n",
    "age = np.random.randint(20,40,7) \n",
    "gender =['M','M','F','M','M','M','M']\n",
    "\n",
    "datadict = {'name':namelist, 'salary':salary, 'gender':gender, 'age':age}\n",
    "datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employee=pd.DataFrame(datadict)\n",
    "df_employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-directive",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sales = pd.read_excel('datasets/pandas/sample_sales.xlsx')\n",
    "print(df_sales)\n",
    "print(df_sales.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_sales = df_sales.melt(id_vars=['StoreId','SoreName'],var_name='Month',value_name='SalesValue')\n",
    "#df_melt_sales = df_sales.melt(id_vars=['StoreId'])\n",
    "print(df_melt_sales.head(10))\n",
    "print(df_melt_sales.tail(10))\n",
    "print(df_melt_sales.shape)\n",
    "print(df_melt_sales.SalesValue.mean())\n",
    "print(df_melt_sales.sort_values(['StoreId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceacdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt_sales.columns = ['StoreId', 'StoreName', 'Month', 'SalesValue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b403c",
   "metadata": {},
   "source": [
    "### Pivot_table\n",
    "\n",
    "Pivot_table is used to aggregate the data based on some key columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregating data based on stores.\n",
    "pd.pivot_table(df_melt_sales, index='StoreId',values='SalesValue',aggfunc=['min','max','sum','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccfeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregating data by Month\n",
    "pd.pivot_table(df_melt_sales, index='Month',values='SalesValue',aggfunc=['min','max','sum','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wide to long using melt()\n",
    "df_melt=df_employee.melt(id_vars=['name'])\n",
    "df_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wide to long using melt()\n",
    "df_melt=df_employee.melt(id_vars=['gender'], value_vars=['name','age'])\n",
    "df_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-authorization",
   "metadata": {},
   "source": [
    "### Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading from a CSV File\n",
    "df_sales = pd.read_csv('datasets/pandas/bigmarket.csv')\n",
    "\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating pivot table\n",
    "pd.pivot_table(df_sales, index='Month', values='Sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-genetics",
   "metadata": {},
   "source": [
    "By default, the aggregate function is average (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating pivot table\n",
    "pd.pivot_table(df_sales, index='Month', values='Sales', aggfunc=['sum','mean','min','max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-dutch",
   "metadata": {},
   "source": [
    "### Cross Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-reynolds",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Preparing the data to demonstrate various types of joins\n",
    "df_cars = pd.read_excel('datasets/pandas/dictionary_data.xlsx',sheet_name='Car')\n",
    "df_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross Table\n",
    "pd.crosstab(df_cars.Car, df_cars.Color, rownames=['Car'],colnames=['Color'], values=df_cars.Sales,aggfunc=['sum','mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-butterfly",
   "metadata": {},
   "source": [
    "### Dataframe Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the data to demonstrate various types of joins\n",
    "df_ins = pd.read_csv('datasets/Dataframe Operations/insurance_data_with_dups.csv')\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e075366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-encyclopedia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Checking duplicates\n",
    "dups = df_ins[df_ins.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fc602",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636143c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ins.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking duplicaes without patiend_id and dayofmonth columns\n",
    "df_ins.drop(['patientid','dayofmonth'], axis='columns',inplace=True)\n",
    "#df_ins.head()\n",
    "print(df_ins.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ins.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting all duplicates except their first occurrance\n",
    "df_ins_dups = df_ins[df_ins.duplicated(keep='first')]\n",
    "print(df_ins_dups.head())\n",
    "print(df_ins.shape)\n",
    "print(df_ins_dups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting all duplicates except their first occurrance with selected columns\n",
    "df_ins_dups = df_ins[df_ins.duplicated(['age','gender','claim'],keep='first')]\n",
    "print(df_ins_dups.head())\n",
    "print(df_ins_dups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping Duplicates\n",
    "print(df_ins.shape)\n",
    "df_ins_wodups = df_ins.drop_duplicates(keep='first')\n",
    "print(df_ins_wodups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72de6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.iloc[1340:1379]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-patrick",
   "metadata": {},
   "source": [
    "### Dropping Rows and Columns from dataframe\n",
    "\n",
    "The drop() is used to drop rows and columns from a dataframe. To drop rows, we have to use the dataframe row index.  To drop the columns we have use column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the data to demonstrate various types of joins\n",
    "df_ins = pd.read_csv('datasets/Dataframe Operations/insurance_data_with_dups.csv')\n",
    "df_ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To drop rows, we have to use the dataframe row index.  To drop the columns we have use column names.\n",
    "print(\"Insurance Data Shape: \",df_ins.shape)\n",
    "## Dropping firsts 4 rows\n",
    "df_ins1 = df_ins.drop(index = range(4))\n",
    "df_ins1.head()\n",
    "print(\"After Removing first 4 rows :\", df_ins1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping Columns\n",
    "df_ins1 = df_ins.drop(['patientid'], axis=1)\n",
    "df_ins1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using inplace and dropping multiple columns\n",
    "df_ins.drop(['patientid','dayofmonth'], axis=1,inplace=True)\n",
    "print(df_ins.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-vegetarian",
   "metadata": {},
   "source": [
    "### Replacing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17500ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e673f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738568cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing sample rows from df_ins\n",
    "print(df_ins.head())\n",
    "\n",
    "df_ins = df_ins.replace('northwest','North West')\n",
    "\n",
    "print(df_ins.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To replace multiple values\n",
    "df_ins = df_ins.replace(['northeast','southeast','southwest','northwest'],['North East','South East','South West','North West'])\n",
    "df_ins.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To count number of records in each category\n",
    "print(df_ins['region'].value_counts())\n",
    "print(df_ins['gender'].value_counts())\n",
    "print(df_ins['diabetic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To replace a specific column\n",
    "df_ins['smoker'] = df_ins['smoker'].replace(['Yes','No'],['Smoker','No Smoker'])\n",
    "print(df_ins.head())\n",
    "df_ins.smoker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ins.columns)\n",
    "#df_ins['high_bmi']\n",
    "## Inserting a column on a specific position\n",
    "df_ins.insert(3,'high_bmi',np.nan)\n",
    "df_ins.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5fdd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace values using .loc \n",
    "df_ins.loc[df_ins['bmi'] > 32, 'high_bmi'] = 'Yes'\n",
    "df_ins.loc[df_ins['bmi'] <= 32, 'high_bmi'] = 'No'\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us first update the column value with np.nan\n",
    "df_ins.high_bmi = np.nan\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace values using np.where\n",
    "df_ins['high_bmi'] = np.where((df_ins['bmi'] > 32),'Yes',df_ins['high_bmi'])\n",
    "df_ins['high_bmi'] = np.where((df_ins['bmi'] <= 32),'No',df_ins['high_bmi'])\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us first update the column value with np.nan\n",
    "df_ins.high_bmi = np.nan\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace values using .loc \n",
    "df_ins.loc[df_ins['bmi'] > 32, 'high_bmi'] = 'Yes'\n",
    "# df_ins.loc[df_ins['bmi'] <= 32, 'high_bmi'] = 'No'\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using fillna function to replace the remaining NaN values with 'No'\n",
    "df_ins['high_bmi'].fillna('No',inplace=True)\n",
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-maria",
   "metadata": {},
   "source": [
    "### Grouping Data from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4515b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Python Learning\\\\Imarticus'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fd5db8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ins = pd.read_csv(\"datasets/dataframe operations/insurance_data_with_day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e886e500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientid</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>diabetic</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>male</td>\n",
       "      <td>23.2</td>\n",
       "      <td>91</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1121.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>30.1</td>\n",
       "      <td>87</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1131.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>33.3</td>\n",
       "      <td>82</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1135.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>male</td>\n",
       "      <td>33.7</td>\n",
       "      <td>80</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>northwest</td>\n",
       "      <td>1136.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>34.1</td>\n",
       "      <td>100</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>northwest</td>\n",
       "      <td>1137.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientid  dayofmonth  age gender   bmi  bloodpressure diabetic  children  \\\n",
       "0          1          19   39   male  23.2             91      Yes         0   \n",
       "1          2           8   24   male  30.1             87       No         0   \n",
       "2          3          11   27   male  33.3             82      Yes         0   \n",
       "3          4           5   37   male  33.7             80       No         0   \n",
       "4          5          21   30   male  34.1            100       No         0   \n",
       "\n",
       "  smoker     region    claim  \n",
       "0     No  southeast  1121.87  \n",
       "1     No  southeast  1131.51  \n",
       "2     No  southeast  1135.94  \n",
       "3     No  northwest  1136.40  \n",
       "4     No  northwest  1137.01  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17ccff3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      678\n",
       "female    662\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ins.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c256bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "gendergroup = df_ins.groupby(['gender'])\n",
    "print(type(gendergroup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "desperate-acrylic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "    patientid  dayofmonth  age  gender   bmi  bloodpressure diabetic  \\\n",
      "24         25          18   50  female  20.8             85      Yes   \n",
      "26         27          26   36  female  26.7             97      Yes   \n",
      "28         29          21   58  female  31.1             87       No   \n",
      "29         30           8   35  female  31.4             93       No   \n",
      "33         34          17   52  female  36.9             81       No   \n",
      "\n",
      "    children smoker     region    claim  \n",
      "24         0     No  southeast  1607.51  \n",
      "26         0     No  southeast  1615.77  \n",
      "28         0     No  southeast  1621.88  \n",
      "29         0     No  southeast  1622.19  \n",
      "33         0     No  southeast  1629.83  \n",
      "male\n",
      "   patientid  dayofmonth  age gender   bmi  bloodpressure diabetic  children  \\\n",
      "0          1          19   39   male  23.2             91      Yes         0   \n",
      "1          2           8   24   male  30.1             87       No         0   \n",
      "2          3          11   27   male  33.3             82      Yes         0   \n",
      "3          4           5   37   male  33.7             80       No         0   \n",
      "4          5          21   30   male  34.1            100       No         0   \n",
      "\n",
      "  smoker     region    claim  \n",
      "0     No  southeast  1121.87  \n",
      "1     No  southeast  1131.51  \n",
      "2     No  southeast  1135.94  \n",
      "3     No  northwest  1136.40  \n",
      "4     No  northwest  1137.01  \n"
     ]
    }
   ],
   "source": [
    "for name, grp in gendergroup:\n",
    "    print(name)\n",
    "    print(grp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "loose-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340, 11)\n",
      "(662, 11)\n",
      "male      678\n",
      "female    662\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## using get_group to get the dataframes\n",
    "df_female = gendergroup.get_group('female')\n",
    "#print(df_female.head())\n",
    "print(df_ins.shape)\n",
    "print(df_female.shape)\n",
    "print(df_ins.gender.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "organic-graphics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        patientid  dayofmonth  age   bmi  bloodpressure diabetic  children  \\\n",
      "gender                                                                       \n",
      "female         25           1   25  16.8             80       No         0   \n",
      "male            1           1   18  16.0             80       No         0   \n",
      "\n",
      "       smoker     region    claim  \n",
      "gender                             \n",
      "female     No  northeast  1607.51  \n",
      "male       No  northeast  1121.87  \n"
     ]
    }
   ],
   "source": [
    "## Printing the min of each group\n",
    "print(gendergroup.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing the average of each group\n",
    "print(gendergroup.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5de9cd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     1066\n",
       "Yes     274\n",
       "Name: smoker, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ins.smoker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dress-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender  smoker\n",
       "female  No         8762.297367\n",
       "        Yes       30678.996261\n",
       "male    No         8061.539383\n",
       "        Yes       33042.006226\n",
       "Name: claim, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ins.groupby(['gender','smoker'])['claim'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.smoker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.groupby(['region'])['claim'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.groupby(['smoker'])['claim'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grouping using multiple columns \n",
    "df_ins.groupby(['region','smoker'])['claim'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sealed-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">claim</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bloodpressure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>gender</th>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">northeast</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">female</th>\n",
       "      <th>No</th>\n",
       "      <td>2755.02</td>\n",
       "      <td>31620.00</td>\n",
       "      <td>1038851.63</td>\n",
       "      <td>12516.284699</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>14283.46</td>\n",
       "      <td>58571.07</td>\n",
       "      <td>812929.32</td>\n",
       "      <td>28032.045517</td>\n",
       "      <td>80</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">male</th>\n",
       "      <th>No</th>\n",
       "      <td>1694.80</td>\n",
       "      <td>32108.66</td>\n",
       "      <td>874390.77</td>\n",
       "      <td>10794.947778</td>\n",
       "      <td>80</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>12829.46</td>\n",
       "      <td>48549.18</td>\n",
       "      <td>1175197.61</td>\n",
       "      <td>30926.252895</td>\n",
       "      <td>80</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">northwest</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">female</th>\n",
       "      <th>No</th>\n",
       "      <td>2117.34</td>\n",
       "      <td>33471.97</td>\n",
       "      <td>1186244.80</td>\n",
       "      <td>8786.998519</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>14711.74</td>\n",
       "      <td>55135.40</td>\n",
       "      <td>860453.92</td>\n",
       "      <td>29670.824828</td>\n",
       "      <td>80</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">male</th>\n",
       "      <th>No</th>\n",
       "      <td>1136.40</td>\n",
       "      <td>30284.64</td>\n",
       "      <td>1136177.91</td>\n",
       "      <td>7283.191731</td>\n",
       "      <td>80</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>15817.99</td>\n",
       "      <td>60021.40</td>\n",
       "      <td>890682.24</td>\n",
       "      <td>30713.180690</td>\n",
       "      <td>81</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">southeast</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">female</th>\n",
       "      <th>No</th>\n",
       "      <td>1607.51</td>\n",
       "      <td>36580.28</td>\n",
       "      <td>1406873.30</td>\n",
       "      <td>7483.368617</td>\n",
       "      <td>80</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>16577.78</td>\n",
       "      <td>63770.43</td>\n",
       "      <td>1189253.57</td>\n",
       "      <td>33034.821389</td>\n",
       "      <td>83</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">male</th>\n",
       "      <th>No</th>\n",
       "      <td>1121.87</td>\n",
       "      <td>27724.29</td>\n",
       "      <td>1207157.49</td>\n",
       "      <td>7360.716402</td>\n",
       "      <td>80</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>17043.34</td>\n",
       "      <td>62592.87</td>\n",
       "      <td>1981641.18</td>\n",
       "      <td>36029.839636</td>\n",
       "      <td>80</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">southwest</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">female</th>\n",
       "      <th>No</th>\n",
       "      <td>1727.79</td>\n",
       "      <td>36910.61</td>\n",
       "      <td>1161006.93</td>\n",
       "      <td>8234.091702</td>\n",
       "      <td>80</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>13844.51</td>\n",
       "      <td>48824.45</td>\n",
       "      <td>665447.76</td>\n",
       "      <td>31687.988571</td>\n",
       "      <td>81</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">male</th>\n",
       "      <th>No</th>\n",
       "      <td>1252.41</td>\n",
       "      <td>27941.29</td>\n",
       "      <td>966212.77</td>\n",
       "      <td>8188.243814</td>\n",
       "      <td>80</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>15820.70</td>\n",
       "      <td>52590.83</td>\n",
       "      <td>1206157.96</td>\n",
       "      <td>32598.863784</td>\n",
       "      <td>81</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            claim                                      \\\n",
       "                              min       max         sum          mean   \n",
       "region    gender smoker                                                 \n",
       "northeast female No       2755.02  31620.00  1038851.63  12516.284699   \n",
       "                 Yes     14283.46  58571.07   812929.32  28032.045517   \n",
       "          male   No       1694.80  32108.66   874390.77  10794.947778   \n",
       "                 Yes     12829.46  48549.18  1175197.61  30926.252895   \n",
       "northwest female No       2117.34  33471.97  1186244.80   8786.998519   \n",
       "                 Yes     14711.74  55135.40   860453.92  29670.824828   \n",
       "          male   No       1136.40  30284.64  1136177.91   7283.191731   \n",
       "                 Yes     15817.99  60021.40   890682.24  30713.180690   \n",
       "southeast female No       1607.51  36580.28  1406873.30   7483.368617   \n",
       "                 Yes     16577.78  63770.43  1189253.57  33034.821389   \n",
       "          male   No       1121.87  27724.29  1207157.49   7360.716402   \n",
       "                 Yes     17043.34  62592.87  1981641.18  36029.839636   \n",
       "southwest female No       1727.79  36910.61  1161006.93   8234.091702   \n",
       "                 Yes     13844.51  48824.45   665447.76  31687.988571   \n",
       "          male   No       1252.41  27941.29   966212.77   8188.243814   \n",
       "                 Yes     15820.70  52590.83  1206157.96  32598.863784   \n",
       "\n",
       "                        bloodpressure       \n",
       "                                  min  max  \n",
       "region    gender smoker                     \n",
       "northeast female No                80  128  \n",
       "                 Yes               80  140  \n",
       "          male   No                80  137  \n",
       "                 Yes               80  140  \n",
       "northwest female No                80  128  \n",
       "                 Yes               80  139  \n",
       "          male   No                80  130  \n",
       "                 Yes               81  137  \n",
       "southeast female No                80  118  \n",
       "                 Yes               83  137  \n",
       "          male   No                80  109  \n",
       "                 Yes               80  140  \n",
       "southwest female No                80  140  \n",
       "                 Yes               81  136  \n",
       "          male   No                80  109  \n",
       "                 Yes               81  140  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Aggregating on multiple columns\n",
    "df_ins.groupby(['region','gender','smoker']).agg({'claim':[min,max, sum,np.mean],'bloodpressure':[min,max]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-blend",
   "metadata": {},
   "source": [
    "### Missing value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "narrow-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1380 entries, 0 to 1379\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   patientid      1380 non-null   int64  \n",
      " 1   dayofmonth     1380 non-null   int64  \n",
      " 2   age            1380 non-null   object \n",
      " 3   gender         1380 non-null   object \n",
      " 4   bmi            1380 non-null   float64\n",
      " 5   bloodpressure  1380 non-null   int64  \n",
      " 6   diabetic       1380 non-null   object \n",
      " 7   children       1380 non-null   int64  \n",
      " 8   smoker         1380 non-null   object \n",
      " 9   region         1380 non-null   object \n",
      " 10  claim          1380 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 118.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1340 entries, 0 to 1339\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   patientid      1340 non-null   int64  \n",
      " 1   dayofmonth     1340 non-null   int64  \n",
      " 2   age            1340 non-null   object \n",
      " 3   gender         1340 non-null   object \n",
      " 4   bmi            1340 non-null   float64\n",
      " 5   bloodpressure  1340 non-null   int64  \n",
      " 6   diabetic       1340 non-null   object \n",
      " 7   children       1340 non-null   int64  \n",
      " 8   smoker         1340 non-null   object \n",
      " 9   region         1340 non-null   object \n",
      " 10  claim          1340 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 125.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Preparing the data to demonstrate various types of joins\n",
    "df_ins = pd.read_csv('datasets/Dataframe Operations/insurance_data_with_dups.csv')\n",
    "print(df_ins.info())\n",
    "\n",
    "## Let us drop the duplicates and keep the first\n",
    "df_ins.drop_duplicates(keep='first', inplace=True)\n",
    "print(df_ins.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1eeb44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins['age'] = df_ins['age'].replace(' ',np.nan)\n",
    "df_ins['age'].replace(' ',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "contemporary-circus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "18    16\n",
       "19    29\n",
       "20    26\n",
       "21    18\n",
       "22    23\n",
       "23    27\n",
       "24    16\n",
       "25    32\n",
       "26    47\n",
       "27    42\n",
       "28    36\n",
       "29    40\n",
       "30    45\n",
       "31    38\n",
       "32    44\n",
       "33    35\n",
       "34    39\n",
       "35    35\n",
       "36    36\n",
       "37    40\n",
       "38    32\n",
       "39    23\n",
       "40    42\n",
       "41    24\n",
       "42    37\n",
       "43    50\n",
       "44    35\n",
       "45    40\n",
       "46    43\n",
       "47    38\n",
       "48    39\n",
       "49    37\n",
       "50    32\n",
       "51    17\n",
       "52    18\n",
       "53    15\n",
       "54    17\n",
       "55    26\n",
       "56    16\n",
       "57    21\n",
       "58    16\n",
       "59    22\n",
       "60    21\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ins.groupby('age')['age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e1290b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patientid        0\n",
       "dayofmonth       0\n",
       "age              0\n",
       "gender           0\n",
       "bmi              0\n",
       "bloodpressure    0\n",
       "diabetic         0\n",
       "children         0\n",
       "smoker           0\n",
       "region           0\n",
       "claim            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ins.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e98d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To  drop the missing value records use dropna method \n",
    "df_ins.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0647ecbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1325, 11)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "lasting-terry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1340 entries, 0 to 1339\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   patientid      1340 non-null   int64  \n",
      " 1   dayofmonth     1340 non-null   int64  \n",
      " 2   age            1340 non-null   object \n",
      " 3   gender         1340 non-null   object \n",
      " 4   bmi            1340 non-null   float64\n",
      " 5   bloodpressure  1340 non-null   int64  \n",
      " 6   diabetic       1340 non-null   object \n",
      " 7   children       1340 non-null   int64  \n",
      " 8   smoker         1340 non-null   object \n",
      " 9   region         1340 non-null   object \n",
      " 10  claim          1340 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 125.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ins.loc[df_ins.age.isnull(),'age'] = 0\n",
    "df_ins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11355c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientid</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>diabetic</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>20.3</td>\n",
       "      <td>90</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>northwest</td>\n",
       "      <td>1242.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>26.7</td>\n",
       "      <td>97</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1615.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>32.9</td>\n",
       "      <td>99</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>southwest</td>\n",
       "      <td>1748.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>28.9</td>\n",
       "      <td>81</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>northwest</td>\n",
       "      <td>2250.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>27.9</td>\n",
       "      <td>82</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>southeast</td>\n",
       "      <td>2867.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>236</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>27.7</td>\n",
       "      <td>82</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>southwest</td>\n",
       "      <td>3554.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>333</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>28.6</td>\n",
       "      <td>80</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>southwest</td>\n",
       "      <td>4687.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>453</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>30.8</td>\n",
       "      <td>92</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>southeast</td>\n",
       "      <td>6313.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>536</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>35.3</td>\n",
       "      <td>100</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>southwest</td>\n",
       "      <td>7348.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>648</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>30.2</td>\n",
       "      <td>95</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>southwest</td>\n",
       "      <td>8968.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>768</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>24.8</td>\n",
       "      <td>89</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10942.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>894</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>26.5</td>\n",
       "      <td>94</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>northeast</td>\n",
       "      <td>12815.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>21.8</td>\n",
       "      <td>105</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>northeast</td>\n",
       "      <td>16657.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1140</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>23.2</td>\n",
       "      <td>86</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>southeast</td>\n",
       "      <td>25081.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1315</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>33.9</td>\n",
       "      <td>97</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>southeast</td>\n",
       "      <td>46889.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      patientid  dayofmonth  age  gender   bmi  bloodpressure diabetic  \\\n",
       "11           12          20  NaN    male  20.3             90      Yes   \n",
       "26           27          26  NaN  female  26.7             97      Yes   \n",
       "67           68          30  NaN  female  32.9             99      Yes   \n",
       "127         128           6  NaN    male  28.9             81       No   \n",
       "184         185          29  NaN    male  27.9             82      Yes   \n",
       "235         236           3  NaN  female  27.7             82       No   \n",
       "332         333          14  NaN  female  28.6             80       No   \n",
       "452         453          20  NaN  female  30.8             92      Yes   \n",
       "535         536          26  NaN  female  35.3            100       No   \n",
       "647         648          11  NaN    male  30.2             95       No   \n",
       "767         768          18  NaN  female  24.8             89      Yes   \n",
       "893         894          30  NaN  female  26.5             94       No   \n",
       "1005       1006          25  NaN  female  21.8            105       No   \n",
       "1139       1140          30  NaN  female  23.2             86       No   \n",
       "1314       1315          23  NaN    male  33.9             97       No   \n",
       "\n",
       "      children smoker     region     claim  \n",
       "11           0     No  northwest   1242.26  \n",
       "26           0     No  southeast   1615.77  \n",
       "67           0     No  southwest   1748.77  \n",
       "127          0     No  northwest   2250.84  \n",
       "184          0     No  southeast   2867.12  \n",
       "235          0     No  southwest   3554.20  \n",
       "332          5     No  southwest   4687.80  \n",
       "452          2     No  southeast   6313.76  \n",
       "535          0     No  southwest   7348.14  \n",
       "647          2     No  southwest   8968.33  \n",
       "767          1     No  northwest  10942.13  \n",
       "893          0     No  northeast  12815.44  \n",
       "1005         1    Yes  northeast  16657.72  \n",
       "1139         0     No  southeast  25081.77  \n",
       "1314         0    Yes  southeast  46889.26  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ins[df_ins.age.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07c432dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins['age'].fillna(df_ins['age'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e537eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins['age'] = df_ins['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36dec12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.014925373134325 37.0\n"
     ]
    }
   ],
   "source": [
    "print(df_ins.age.mean(), df_ins.age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To print only the columns have missing values\n",
    "print(df_ins.columns[df_ins.isnull().any()])\n",
    "\n",
    "## Another way\n",
    "print(df_ins.columns[df_ins.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins = df_ins.astype({'age':int})\n",
    "df_ins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "inclusive-growing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "## Updating the missing values with average value of the same column\n",
    "#df_ins['age'].fillna((df_ins['age'].mean()), inplace = True)\n",
    "df_ins['age'].replace(' ',np.nan, inplace = True)\n",
    "\n",
    "df_ins.isnull().sum()\n",
    "\n",
    "df_ins['age'] = df_ins['age'].astype(int)\n",
    "\n",
    "print(df_ins['age'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27971ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_ins.age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.loc[df_ins.age.isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "closed-crash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patientid        0\n",
       "dayofmonth       0\n",
       "age              0\n",
       "gender           0\n",
       "bmi              0\n",
       "bloodpressure    0\n",
       "diabetic         0\n",
       "children         0\n",
       "smoker           0\n",
       "region           0\n",
       "claim            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Updating the missing values with average value of the same column\n",
    "df_ins['age'].fillna(df_ins['age'].median(), inplace = True)\n",
    "df_ins.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43c8e34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ins.age.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ins.iloc[[11,26]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc1bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
